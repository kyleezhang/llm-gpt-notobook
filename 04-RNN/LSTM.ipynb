{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-18T11:29:49.110914Z",
     "start_time": "2025-06-18T11:29:49.106244Z"
    }
   },
   "source": [
    "sentence = \"我 喜欢 学习 深度 学习\"\n",
    "words = sentence.split()\n",
    "word2idx = {word: idx for idx, word in enumerate(set(words))}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "input_seq = [] # 输入词索引\n",
    "target_seq = [] # 目标词索引\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    input_seq.append(word2idx[words[i]])\n",
    "    target_seq.append(word2idx[words[i + 1]])\n",
    "\n",
    "print(idx2word, input_seq, target_seq)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '深度', 1: '我', 2: '喜欢', 3: '学习'} [1, 2, 3, 0] [2, 3, 0, 3]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:31:10.012217Z",
     "start_time": "2025-06-18T11:31:10.008215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "input_tensor = torch.tensor(input_seq)     # shape: (seq_len,)\n",
    "target_tensor = torch.tensor(target_seq)   # shape: (seq_len,)"
   ],
   "id": "ced6e8f9c77ffaf6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:32:09.481522Z",
     "start_time": "2025-06-18T11:32:09.477043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)                  # shape: (batch, seq_len, embedding_dim)\n",
    "        output, (hn, cn) = self.lstm(embedded)        # output: (batch, seq_len, hidden_dim)\n",
    "        logits = self.fc(output)                      # shape: (batch, seq_len, vocab_size)\n",
    "        return logits"
   ],
   "id": "169d29313f0d7404",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:33:05.274425Z",
     "start_time": "2025-06-18T11:33:04.301165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_tensor = input_tensor.unsqueeze(0)     # shape: (1, seq_len)\n",
    "target_tensor = target_tensor.unsqueeze(0)   # shape: (1, seq_len)\n",
    "model = SimpleLSTM(vocab_size=vocab_size, embedding_dim=16, hidden_dim=32)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_tensor)\n",
    "\n",
    "    output = output.view(-1, vocab_size)\n",
    "    target = target_tensor.view(-1)\n",
    "\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))"
   ],
   "id": "3f3bbb961c4d5216",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.472496\n",
      "Epoch: 0011 cost = 0.349428\n",
      "Epoch: 0021 cost = 0.033909\n",
      "Epoch: 0031 cost = 0.007014\n",
      "Epoch: 0041 cost = 0.003042\n",
      "Epoch: 0051 cost = 0.001956\n",
      "Epoch: 0061 cost = 0.001527\n",
      "Epoch: 0071 cost = 0.001302\n",
      "Epoch: 0081 cost = 0.001155\n",
      "Epoch: 0091 cost = 0.001044\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

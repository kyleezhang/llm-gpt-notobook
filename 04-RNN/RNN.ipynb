{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RNN的基本原理是通过循环来传递隐藏状态信息，从而实现对序列数据的建模。",
   "id": "fe60a79d5936f9b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:09:55.664675Z",
     "start_time": "2025-06-16T13:09:55.661678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"我 喜欢 学习 深度 学习\"\n",
    "words = sentence.split()\n",
    "word2idx = {word: idx for idx, word in enumerate(set(words))}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "input_seq = [] # 输入词索引\n",
    "target_seq = [] # 目标词索引\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    input_seq.append(word2idx[words[i]])\n",
    "    target_seq.append(word2idx[words[i + 1]])\n",
    "\n",
    "print(idx2word, input_seq, target_seq)"
   ],
   "id": "e471678a2650e14f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '喜欢', 1: '我', 2: '学习', 3: '深度'} [1, 0, 2, 3] [0, 2, 3, 2]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:14:06.227890Z",
     "start_time": "2025-06-16T13:14:03.907532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "input_tensor = torch.tensor(input_seq)     # shape: (seq_len,)\n",
    "target_tensor = torch.tensor(target_seq)   # shape: (seq_len,)\n",
    "print(input_tensor, target_tensor)"
   ],
   "id": "d9289355a8d80510",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2, 3]) tensor([0, 2, 3, 2])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:28:51.966731Z",
     "start_time": "2025-06-16T13:28:51.957909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size = embedding_dim, hidden_size=hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size) # 输出词表中每个词的概率分布\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                # (batch, seq_len) → (batch, seq_len, embed_dim)\n",
    "        output, hidden = self.rnn(x)         # output: (batch, seq_len, hidden_dim)\n",
    "        logits = self.fc(output)             # (batch, seq_len, vocab_size)\n",
    "        return logits"
   ],
   "id": "efe03c308595db57",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:32:02.757979Z",
     "start_time": "2025-06-16T13:32:01.815728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RNN(vocab_size=vocab_size, embedding_dim=16, hidden_dim=32)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):  # 假设训练 100 轮\n",
    "    optimizer.zero_grad()             # 清空梯度\n",
    "    output = model(input_tensor)      # 前向传播，输出 shape: (1, seq_len, vocab_size)\n",
    "\n",
    "    # 注意：loss 函数要的输入是 (N, C)，目标是 (N,)\n",
    "    output = output.view(-1, vocab_size)        # reshape 成 (seq_len, vocab_size)\n",
    "    target = target_tensor.view(-1)             # reshape 成 (seq_len,)\n",
    "\n",
    "    loss = loss_fn(output, target)    # 计算交叉熵损失\n",
    "    loss.backward()                   # 反向传播\n",
    "    optimizer.step()                  # 更新参数\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n"
   ],
   "id": "e3212252bf579f95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.371842\n",
      "Epoch: 0011 cost = 0.064620\n",
      "Epoch: 0021 cost = 0.006817\n",
      "Epoch: 0031 cost = 0.002382\n",
      "Epoch: 0041 cost = 0.001422\n",
      "Epoch: 0051 cost = 0.001089\n",
      "Epoch: 0061 cost = 0.000930\n",
      "Epoch: 0071 cost = 0.000834\n",
      "Epoch: 0081 cost = 0.000763\n",
      "Epoch: 0091 cost = 0.000705\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
